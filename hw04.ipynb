{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ASTR 21000, Winter 2020\n",
    "\n",
    "## Homework Assignment 4 (55 points + 15 extra-credit points)\n",
    "\n",
    "## Drawing samples from distribution and implementing Differential Evolution minimization\n",
    "\n",
    "### Distributed: Monday, February 24\n",
    "\n",
    "### Due: Friday,  February 28 at 11:59pm \n",
    "\n",
    "#### Exercises you need to do for the assignment grade are tasks in Exercises 1, 2, and 3 along with relative difficulty of each task in the exercise denoted by associated points\n",
    "\n",
    "#### Please submit you notebook (i.e. its *.ipynb file) as an attachment via Canvas. You can also attach other files, if needed to your submission. Make sure that all of the cells in the notebook have output that you want, when you run all cells just before the submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Jupyter notebooks with class notes and assignments: https://github.com/a-kravtsov/a211w20\n",
    "\n",
    "#### Slack workspace for this class: https://a211w20.slack.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import packages needed by the codes below. Run this cell first before using these codes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# use jupyter \"magic\" command to tell it to embed plot into the notebook \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from codes.plot_utils import plot_pretty\n",
    "plot_pretty(fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 (10 points): drawing pseudo-random integers and Gaussian pseudo-random numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background.** During the past weeks (as well as before) we have encountered algorithms that rely on drawing random numbers with a given distribution. Most common case is random numbers, either integer or real, that are *uniformly distributed* within a given range. Uniform distribution means that all numbers within range have equal probability to be drawn, so for example, if we randomly draw uniformly distributed integers from 0 to 10, all numbers 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 will be drawn equal number of times after sufficiently large number of draws. \n",
    "\n",
    "In particular, in the *random walk* and *differential evolution* algorithms i described in class on Friday (see <a href=\"05_optimization.ipynb\"><tt>05_optimization.ipynb</tt></a> notebook) random samples (draws) from Gaussian and uniform distribution are used.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, the differential evolution (DE) algorithm discussed on Friday and can be described by the following pseudo-code: \n",
    "\n",
    "    def minimize_by_differential_evolution(func, x0, atol=1.e-6, s=1.0, bounds=None)\n",
    "    \n",
    "        npop = np.size(x0)[0] # the number of population members\n",
    "        fnow = func(xnow)\n",
    "        xnow = np.copy(x0)\n",
    "        xnext = np.zeros_like(xnow)\n",
    "        #....\n",
    "        while some convergence criterion is not met: \n",
    "            # xnow is a vector of coordinate vectors of the current population\n",
    "            # xnext is a vector of coordinate vector of the next gen population\n",
    "            for i in range(npop):\n",
    "                # generate random indices  ir1, ir2, ir3 \n",
    "                # where all indices are not equal to each other and not equal to i\n",
    "                # s can be a constant for large npop, but it's more safe to make it a Gaussian random number\n",
    "                xtry = xnow[ir3] + s * (xnow[ir1] - xnor[ir2])\n",
    "                if xtry is within bounds and func(xtry) <= fnow[i]:\n",
    "                    xnext[i] = xtry\n",
    "                else:\n",
    "                    xnext[i] = xnow[i]\n",
    "                \n",
    "        return xnext\n",
    "        \n",
    "As we can see, the algorithm is quite simple, but it requires generation of unique random indices ir1, ir2, ir3 different from each other and from i, as well as a random Gaussian number to be used for scaling parameter s for reasons that are described in <a href=\"05_optimization.ipynb\"><tt>05_optimization.ipynb</tt></a> notebook. \n",
    "\n",
    "In this exercise, you will learn and practice drawing such random numbers using numpy routines. In classes this week we will also learn the algorithms used in these routines.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are you learning in this exercise: \n",
    "\n",
    "* How to draw random numbers and randomly permute number sequences using numpy routines.\n",
    "* Some properties of the random draws for small sample sizes. \n",
    "* How to check the distribution of random draws using a histogram. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1a. (3 points)** <tt>nrand</tt> random intergers distributed uniformly in the range <tt>imin</tt> to <tt>imax</tt> can be drawn using routine <a href=\"https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.random.random_integers.html\">numpy.random.random_integers<tt></tt></a>  as\n",
    "\n",
    "        irand = np.random.random_integers(low=imin, high=imax, size=nrand)\n",
    "\n",
    "where <tt>irand</tt> will be a vector of randomly drawn integers in the required range. Use this function to generate <tt>nrand=10</tt>, <tt>nrand=20</tt>, <tt>nrand=30</tt> numbers in the range from 0 to <tt>nrand-1</tt> and print them out. Examine the numbers and comment on their properties: do they look random? do the numbers repeat (if so, is this ok or note)? Comment on whether this function can be used to generate indices <tt>ir1, ir2, ir3</tt> unique and different from <tt>i</tt> in the DE algorithm shown above, and, if so, how would you do this. \n",
    "\n",
    "Note: numpy has another routine <a href=\"https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.random.randint.html\"><tt>numpy.random.randint</tt></a> to generate random integers, but this routine generates numbers excluding <tt>imax</tt>, i.e. in the semi-open interval <tt>[imin,imax)</tt>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1b. (2 points)** Another possibility of producing indices <tt>ir1, ir2, ir3</tt> is to take an ordered list of integer numbers from 0 to <tt>npop-1</tt> and randomly *permute* its elements using numpy function <a href=\"https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.permutation.html\"><tt>numpy.random.permutation</tt></a>. Experiment with this function for a vector of a small size (say 10) and examine its effect on the order of the vector elements. Develop an algorithm of producing  <tt>ir1, ir2, ir3</tt> indices for the DE algorithm using this function. Do you see any advantages or disadvantages of this method over the method discussed in 1a? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1c (5 points).** Gaussian random numbers to produce stochastic scaling parameter $s$ can be drawn using routine <a href=\"https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.normal.html\"><tt>numpy.random.normal</tt></a>. For example to produce <tt>nrnd</tt> pseudo-random draws from a Gaussian distribution with the mean <tt>mu</tt> and dispersion <tt>sigma</tt> we use\n",
    "\n",
    "    xgauss = np.random.normal(loc=mu, scale=sigma, size=nrnd)\n",
    "    \n",
    "Random numbers are samples drawn from a given probability distribution function (pdf), if the probability density of the draws is described by the pdf function. Thus, we can generate a sufficiently large number of pseudo-random numbers using <a href=\"https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.normal.html\"><tt>numpy.random.normal</tt></a>, as shown above, and then test whether they follow a Gaussian distribution. Namely, we can construct their histogram, which is the density of samples per histogram bins, and check whether the histogram is described by the Gaussian distribution: \n",
    "\n",
    "$$p_{\\rm G}(x) =\\frac{1}{\\sqrt{2\\pi}\\sigma}\\, \\exp\\left[-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2\\right].$$\n",
    "\n",
    "Choose the number of bins that should be appropriate for such bins and estimate the required number of random draws using what you learned about histogram binning previously, and explain your choice. Generate the corresponding number of random draws, histogram them and compare with the equation for the Gaussian pdf above.\n",
    "\n",
    "*Hint:* when doing this test, use the option <tt>density=True</tt> for the pyplot's <tt>hist</tt> function, so that the area under the histogram is 1.0, as it should be for a pdf. For example, for the above Gaussian pdf equation:\n",
    "\n",
    "$$\\int\\limits_{-\\infty}^\\infty p_{\\rm G}(x)dx = 1.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 (20 points): drawing pseudo-random numbers following a given distribution.\n",
    "\n",
    "**Background: the inverse transform method.** There is a class of algorithms to generate random numbers drawn from a given distribution function. All of these algorithms are based on the algorithm to generate uniformly distributed random numbers that is described in <a href=\"06a_prngs.ipynb\"><tt>06a_prngs.ipynb</tt></a> notebook and will be discussed in class on Wednesday. \n",
    "\n",
    "One of the most commonly used algorithms to draw samples from a given 1-dimensional distribution $p(x)$ is called *the inverse transform method,* which uses the cumulative distribution function of the target pdf $p(x)$ normalized to 1 at some interval $[a,b]$ that we want to sample:\n",
    "\n",
    "$$F(\\xi) = \\int\\limits_{a}^\\xi p(x) dx;\\ \\ \\ \\mathrm{where}\\ \\ \\xi\\in[a,b],\\ F\\in[0,1],\\ \\ \\mathrm{and}\\ \\  \\int\\limits_a^b p(x)dx =1$$\n",
    "\n",
    "to generate samples of $p(x)$. Namely, if $y=F(\\xi)$ can be inverted either analytically or numerically so that we can easily compute $\\xi$ given a value of $y=F(\\xi)$, then $\\xi$ will be samples of $p(x)$, if $y$ are samples of the uniform distribution defined on the interval $[0,1)$. \n",
    "\n",
    "See <a href=\"06c_distribution_sampling.ipynb\"><tt>06c_distribution_sampling.ipynb</tt></a> notebook for details on the history and logic behind this method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are you learning in this exercise: \n",
    "\n",
    "* How to normalize a probability distribution function and compute its cumulative distribution.\n",
    "\n",
    "* How to use the inverse transform method to draw pseudo-random samples of 1-dimensional distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2a (10 points).** \n",
    "Write a routine to sample the following distribution that depends on parameter $a$: \n",
    "\n",
    "$$g(x)=\n",
    " \\begin{cases}\n",
    "            1/\\sqrt{x},&\\  \\mathrm{for}\\ \\ x\\in[1/a,a],\\\\\n",
    "            0, &    \\mathrm{otherwise.\\ }\n",
    "    \\end{cases}$$\n",
    "    \n",
    "Note that the above distribution is *not* a pdf, because it is not normalized to 1.0 on the interval $[1/a,a]$. Thus, you should compute the normalization constant first. You should also compute the cumulative distribution function $F(x)$ for the normalized $\\tilde{g}(x)$ and its inverse.   \n",
    "\n",
    "Your routine should take as input parameter $a$ and the number of samples, $N_s$, to be generated and return a vector of $N_s$, pseudo-random numbers distributed with $g(x)$ distribution, for example:\n",
    "\n",
    "    def gdist(nrnd = 1, a = 2.0):\n",
    "        \"\"\"\n",
    "        function to sample distribution g(x) = 1/sqrt(x) for x in [1/a,a] and g(x)=0 otherwise.\n",
    "    \n",
    "        Parameters:\n",
    "        -----------\n",
    "        nrnd: integer (default is 1)\n",
    "            number of pseudo-random draws of g(x) to generate\n",
    "        a: real \n",
    "           parameter defining the range of the distribution (see above\n",
    "       \n",
    "        Returns: \n",
    "        --------\n",
    "        a numpy real 1d vector of size nrnd\n",
    "        (pseudo-random numbers distributed with g(x), as defined above \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "For efficiency, your routine must be written using numpy vector operations and should not use loops. \n",
    "\n",
    "The vector of <tt>nrnd</tt> uniformly distributed pseudo-random numbers in the interval $[0,1)$ can be generated using routine <a href=\"https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.uniform.html\"><tt>numpy.random.uniform</tt></a> as \n",
    "    \n",
    "    yrnd = np.random.uniform(size=nrnd)\n",
    "\n",
    "Note that the sampling routine you develop here will be used in the implementation of the \"affine-invariant\" Markov Chain Monte Carlo (MCMC) sampling method of Goodman & Weare as part of the homework 4 assignment.  This is yet another example of a simpler method problem used as an element of a more complex algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2b (10 points).** Suppose we want to draw samples from a more complicated pdf, $p(x) = A x^{-\\alpha}\\exp[-x/b]$, for which cumulative distribution function cannot be inverted analytically. \n",
    "\n",
    "Design and describe strategy to use the inverse transform method in such case using techniques you have already learned in this course (3 points). Implement sampling of this function using your strategy and demonstrate that your samples follow the target distribution using histogram of the samples (i.e., test similar to that used for the Gaussian distribution in 1c above). (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: implementing and testing a Differential Evolution algorithm (25 points + 10 extra-credit points)\n",
    "\n",
    "**Background.** Minimization in many dimensions is generally a complicated task. However, a class of <a href=\"https://en.wikipedia.org/wiki/Differential_evolution\">Differential Evolution</a> (DE) algorithms developed from the initial ideas of R. Storn and K. Price in 1997 (<a href=\"https://link.springer.com/article/10.1023%2FA%3A1008202821328\">Storn & Price 1997</a>), are relatively simple to implement, work in arbitrary number of dimensions, do not require function derivatives, allow imposing bounds on the domain, and are quite efficient in minimizing multi-dimensional functions.\n",
    "\n",
    "### What you are learning in this exercise:\n",
    "\n",
    "* how to implement a general multi-dimensional minimization DE algorithm\n",
    "* how to apply techniques you learn in the exercise 1 above in practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3a. (20 points)** Use pseudo-code of the DE algorithm in exercise 1 to implement DE minimization routine with the following interface (15 points):\n",
    "\n",
    "    def minimize_by_differential_evolution(func, x0, atol=1.e-6, s=1.0, sigs=0.1, bounds=None):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        ------------\n",
    "        func - Python function object\n",
    "               function to minimize, should expect x0 as a parameter vector\n",
    "        x0   - vector of real numbers of shape (npop, nd), \n",
    "                where npop is population size and nd is the number of func parameters\n",
    "        atol - real\n",
    "                absolute tolerance threshold for change of population member positions\n",
    "        s    - real \n",
    "                mean of the scaling parameter s\n",
    "        sigs - real \n",
    "                rms dispersion of s for drawing Gaussian random numbers center on s\n",
    "        bounds - array of tuples \n",
    "                bounds for the minimization exploration; define the region in which to search for the minimum\n",
    "        \"\"\"\n",
    "        \n",
    "Try to \"vectorize\" as much of the algorithm as possible.\n",
    "        \n",
    "Assuming that we are searching for a minimum within some rectangular domain defined by the minimum and maximum values along each coordinate axis: $\\mathbf{x}_{\\rm min}$ and $\\mathbf{x}_{\\rm max}$, we can initialize the population members as \n",
    "\n",
    "$$\\mathbf{x}_0 = \\mathbf{x}_{\\rm min} + (\\mathbf{x}_{\\rm max}-\\mathbf{x}_{\\rm min}) \\times \\mathrm{rand}(0,1),$$\n",
    "\n",
    "where $\\mathrm{rand}(0,1)$ is a random number uniformly distributed from 0 to 1, generated using <tt>np.random.uniform</tt>.  \n",
    "\n",
    "Test your implementation in 2D and 5D using the Rosenbrock function similarly how optimization routines were tested in the <a href=\"05_optimization.ipynb\"><tt>05_optimization.ipynb</tt></a> notebook and present results of your tests along with your implementation (2 points). \n",
    "\n",
    "Experiment with the size of the population and values of the parameter $s$ timing how long it takes your function to find the minimum. Are the results robust to population size and $s$? Briefly describe results of your findings (3 points). If you do not succeed implementing routine fully, you can still do this part of the task using routine <tt>scipy.optimize.differential_evolution</tt>, as illustrated in the <a href=\"05_optimization.ipynb\"><tt>05_optimization.ipynb</tt></a> notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3b (5 points).** Use the DE routine you implemented to find the minimum of the $\\chi^2$ function as a function of $\\Omega_{\\rm m0}$, $\\Omega_\\Lambda$, and $\\tilde{M}_0$ that you used in hw 3. Check that results you get are similar to what you obtained in hw 3. \n",
    "\n",
    "If you do not succeed implementing routine fully, you can still do this part of the task using routine <tt>scipy.optimize.differential_evolution</tt>, as illustrated in the <a href=\"05_optimization.ipynb\"><tt>05_optimization.ipynb</tt></a> notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3c (extra-credit 15 points).** If you implement DE minimization routine successfully in 3a, you can parallelize it using MPI routines by parallelizing mutation and selection stages during each evolutionary iteration for subsets of the population members, similarly to the parallelization of the integration described in the extra-credit exercise in hw 1. \n",
    "\n",
    "Present parallelized implementation and tests showing 1) that it works identically to the unparallelized version and 2) timing showing how the execution time scales with the number of MPI processes on different number of processing cores. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
