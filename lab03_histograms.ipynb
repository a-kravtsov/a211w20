{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ASTR 2100, Winter 2020\n",
    "\n",
    "## Lab 3 \n",
    "\n",
    "###  Monday, February 10\n",
    "\n",
    "The exercises in this lab will constitute the first exercise of HW 3, which will be distributed on Monday, evening. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Jupyter notebooks with class notes and assignments: https://github.com/a-kravtsov/a211w20\n",
    "\n",
    "#### Slack workspace for this class: https://a211w20.slack.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import packages needed by the codes below. Run this cell first before using these codes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# use jupyter \"magic\" command to tell it to embed plot into the notebook \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from codes.plot_utils import plot_pretty\n",
    "plot_pretty(fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: 1D and 2D histograms of data. (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background.** I introduced the issue of choosing histogram bin width in class and you can find heuristic criteria and objective methods (Shimazaki-Shinomoto method and Knuth method) of estimating the bin width (or, equivalently, the number of bins for a given range of data) in the notebook <a href=\"04_histograms.ipynb\"><tt>04_histograms.ipynb</tt></a>. \n",
    "\n",
    "In that notebook I used the heavy element abundances of globular clusters in our Milky Way galaxy to illustrate that the structure in that distribution (in particular two peaks, or, \"modes\" in the distribution) is likely not real, because when histogram is constructed with the 6-8 bins suggested objective methods, no two peaks are apparent. \n",
    "\n",
    "In this exercise, you will explore how these criteria and methods work in another specific application: distribution of colors of galaxies. For this, you will first get your sample of galaxies from the Sloan Digital Sky Survey (SDSS) data bases, as described in the companion <a href=\"hw03_background_sdss.ipynb\"><tt>hw03_background_sdss.ipynb</tt></a> notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What you are learning in this exercise\n",
    "\n",
    "* To use basic SQL commands to query an astronomical data base.\n",
    "* Some basic facts about \"colors\" of galaxies in nearby Universe. \n",
    "* How to use objective criteria to estimate bin width and the number of bins to be used in a histogram. \n",
    "* How to evaluate whether certain features in the distribution of some quantity are real or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1a. (5 points)** Acquire SDSS galaxy sample, as described in <a href=\"hw03_background_sdss.ipynb\"><tt>hw03_background_sdss.ipynb</tt></a> notebook. Run the cells below and construct the histogram using the plotting routine, as shown. \n",
    "\n",
    "Note that you can pass the number of bins as an integer to the routine via <tt>bins</tt> parameter. Plot histogram of $g-r$ colors of galaxies for different number of bins and note and briefly describe any changes in the appearance of the histogram. (2 points)\n",
    "\n",
    "You can also pass string options that are accepted by the <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html\"><tt>numpy.histogram</tt></a> routine: <tt>'auto', 'sturges', 'fd', 'scott', 'rice', 'sqrt'.</tt> The meaning of these options and the heuristic models for bin number or bin width these correspond to is explained in the <a href=\"04_histograms.ipynb\"><tt>04_histograms.ipynb</tt></a> notebook. Explore how the histogram changes when each of these options is used and briefly describe your results. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "\n",
    "hdulist = fits.open('data/sdss_galaxies.fits') \n",
    "\n",
    "# data table in the FITS is a dictionary, which we will convert to the numpy dictionary (record)\n",
    "data = np.asarray(hdulist[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will give us names of columns and their data types\n",
    "print(data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data in dictionaries can be accessed by the name of the corresponding variable. For example, we can subselect indices of data that satisfied a set of constraints as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmin, zmax = 0.01, 0.14\n",
    "rmin, rmax = 12, 17.77\n",
    "isel = ((data['r'] > rmin) & (data['r'] < rmax) & (data['z'] > zmin) & (data['z'] < zmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In astronomy, the different of apparent magnitudes of an object measured in different filters is called \"color,\" in analogy with how our eye converts brightness of light in different parts of the visible spectrum into perceived color. Here we will define $g-r$ color as the different of apparent magnitudes of galaxies in our sample in the $g$ and $r$ filters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g-r color of all galaxies in the selected subsample\n",
    "mr = data['r'][isel]\n",
    "gr = data['g'][isel] - data['r'][isel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.size(gr))\n",
    "print(gr.min(), gr.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.plot_utils import plot_histogram \n",
    "plot_pretty(fontsize=12)\n",
    "\n",
    "plot_histogram(gr, bins='fd', xlabel=r'$g-r\\ \\rm color$', ylabel=r'$N_{\\rm galaxies}$', \n",
    "               plot_title='color distribution of galaxies', figsize=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1b.** (5 points) Change the sample selection below by making redshift range (<tt>zmin, zmax</tt>) and/or range of $r$-band magnitude (<tt>rmin, rmax</tt>) narrower and centered on different values. Using <tt>bins='scott'</tt> for the binning, find a combination of ranges for which the distribution starts to look significantly different from that in 1a. \n",
    "\n",
    "In particular, for some choices it may reveal a new type of structure in the distribution with two distinct peaks. To identify where this happens, it may help to examine the distribution of colors in the $m_r-(g-r)$ plane. To do this, the code below uses routine, which in turn uses <a href=\"\">numpy.histogram2d</a> and the Matplotlib's <tt>colormesh</tt> routine we used before to plot $d_L$ in the $\\Omega_{\\rm m0}-\\Omega_\\Lambda$ plot.  Look for ranges of $m_r$ in the distribution where more interesting structure is present. \n",
    "\n",
    "Briefly describe your exploration and results and show the final plot for which the distribution differs significantly and selection criteria that were used to subselect galaxies in that case. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.plot_utils import plot_2d_dist\n",
    "\n",
    "plot_2d_dist(mr, gr, xlim=[mr.min(), mr.max()], ylim=[0, 1.4],\n",
    "             nxbins=100, nybins=100, \n",
    "             xlabel=r'$m_r$', ylabel=r'$g-r$', figsize=(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1c** (5 points). Given the lesson from binning metallicities of globular clusters in <a href=\"04_histograms.ipynb\"><tt>04_histograms.ipynb</tt></a>, which showed that structure in the distribution may not real, check whether it is still present if the number of bins is estimated using the The Shimazaki-Shinomoto method and Knuth method. Examples of their use can be found in the <a href=\"04_histograms.ipynb\"></a> and their usage for this case is shown in the cells below. Report your results and briefly describe your conclusions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.histtools import shimazaki_shinomoto_rule\n",
    "\n",
    "nss, hss = shimazaki_shinomoto_rule(gr, Nbmin=4, Nbmax=500)\n",
    "\n",
    "print(\"number of bins according to Shimazaki-Shinomoto method is %d\"%nss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.histtools import knuth_bin_width\n",
    "\n",
    "h_knuth, bins_knuth = knuth_bin_width(gr, return_bins=True)\n",
    "\n",
    "n_knuth = np.shape(bins_knuth)[0] - 1\n",
    "print(\"number of bins according to Knuth method is %d\"%n_knuth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.plot_utils import plot_histogram \n",
    "plot_pretty(fontsize=12)\n",
    "\n",
    "plot_histogram(gr, bins=n_knuth, xlabel=r'$g-r\\ \\rm color$', ylabel=r'$N_{\\rm galaxies}$', \n",
    "               plot_title='color distribution of galaxies', figsize=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1d.** (10 points). Based on what you learned from material in <a href=\"04_histograms.ipynb\"><tt>04_histograms.ipynb</tt></a> and in the exercises above, think about, develop, and describe a rough heuristic argument to guide the choice of number of bins in each dimension for a 2-dimensional histogram (5 points). Apply the rule you developed to the histogram of galaxies in the $m_r-(g-r)$ plane suggested in the Task 1b above and show the corresponding plot (2 points). \n",
    "\n",
    "Finally, using the galaxy coordinates <tt>xgal</tt> and <tt>ygal</tt> computed as shown below, plot distribution of galaxies as 2d histogram using routine <tt>plot_2d_dist</tt>, instead of plotting each galaxy as a point, as in the code below. Discuss whether the rule you developed for the number of bins for choosing the number of bins produce reasonable results in this case as well? (3 points). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.constants import clight \n",
    "\n",
    "H0 = 70. \n",
    "d_C = clight * data['z'] / H0 # approximate calculation of comoving distance using Hubble law\n",
    "\n",
    "# conversion of sky coordinates in x-y coordinates. all galaxies are assumed to have the same dec\n",
    "# for visualization purposes\n",
    "ygal = d_C * np.cos(data['ra'] * np.pi / 180.)\n",
    "xgal = d_C * np.sin(data['ra'] * np.pi / 180.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figx = 3.\n",
    "xmin, xmax = -400.,  300.\n",
    "ymin, ymax = -400., -150.\n",
    "\n",
    "\n",
    "fxy = np.abs(ygal.max()-ygal.min()) / np.abs(xgal.max() - xgal.min())\n",
    "figy = figx  * fxy\n",
    "\n",
    "plot_pretty(fontsize=12)\n",
    "fig, ax = plt.subplots(1, 1, sharex=True, figsize=(figx,figy))\n",
    "plt.xlim([xmin, xmax]); plt.ylim([ymin, ymax])\n",
    "\n",
    "ax.scatter(xgal, ygal, s=0.2, lw=0, c='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: using $\\tilde{d}_L$ approximation and supernova type Ia sample to constrain $\\Omega_{\\rm m0}$ and $\\Omega_\\Lambda$\n",
    "\n",
    "The full exercise will be distributed later. In the lab, you can get acquainted with the concept of pickled Python objects for transferring results of the approximation you obtained for $\\tilde{d}_L$ for use in this exercse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "A tutorial on using this method can be found <a href=\"https://thepythonguru.com/pickling-objects-in-python/\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of the method is illustrated below and as you will see is quite simple. \n",
    "\n",
    "Suppose I produced a spline object (class) <tt>spl2d_c</tt> or computed polynomial coefficients in the numpy vector <tt>ac</tt> in exercise 2 of hw 2. \n",
    "\n",
    "By spline object we mean here the instantiated spline class that you can now use for test points as, for example: \n",
    "<tt>spl2d_c(Om0t, OmLt)</tt> (your names for these can of course be different). \n",
    "\n",
    "We can save (or dump in pickle package terminology) these into binary file, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "f = open(\"data/d_L_polycoeffs\", \"wb\")\n",
    "pickle.dump(ac, f) # dump polynomial coefficients into the file\n",
    "f.close()\n",
    "\n",
    "f = open(\"data/d_L_spline\", \"wb\")\n",
    "pickle.dump(spl2d_c, f) # dump 2d spline object into the file\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then read them in a separate python code or notebook as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "f = open(\"data/d_L_spline\", \"rb\")\n",
    "d_l_spl = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"data/d_L_polycoeffs\", \"rb\")\n",
    "ac = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once these are read, we can then use the spline or polynomial coefficients I recovered from the pickle file just as we would use them in they were produced in the same code or notebook, as shown below. \n",
    "\n",
    "Note that I use polynomial of order <tt>px, py = 13, 13</tt> because this is what I concluded produced optimal results in my exercise. Your results may be different. You also should use the best method you chose - there is no need to use both spline *and* polynomial approximation here, only one of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Om0min, Om0max, nOm0 = 0, 1, 100\n",
    "OmLmin, OmLmax, nOmL = 0, 1, 100\n",
    "\n",
    "Om0 = np.linspace(Om0min, Om0max, nOm0)\n",
    "OmL = np.linspace(OmLmin, OmLmax, nOmL)\n",
    "\n",
    "# generate a 2d grid of x and y points\n",
    "Om0g, OmLg = np.meshgrid(Om0, OmL, sparse=False, indexing='ij')\n",
    "\n",
    "dLg = d_l_spl(Om0, OmL)\n",
    "\n",
    "px, py = 13, 13\n",
    "dLpg = np.polynomial.polynomial.polyval2d(Om0g, OmLg, ac.reshape((px+1,py+1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Two warnings about using pickle: \n",
    "\n",
    "* When using binary format for pickle, the resulting pickled object may not be transferrable to another computer, which has different operating system and Python version. So it's best used for internal needs on your machine. \n",
    "\n",
    "\n",
    "* Reading pickled objects produced by someone else is dangerous, because it can execute malicious code upon reading. Thus, use only pickle files produced by you or by someone you trust. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
